{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2422513,"sourceType":"datasetVersion","datasetId":1225408}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Collaborative Filtering Recommendation System","metadata":{}},{"cell_type":"markdown","source":"## Collaborative Filtering Overview\n\n### How It Works\nCollaborative filtering generates user parameter vectors and movie feature vectors by learning from existing ratings. The process involves the following steps:\n\n1. **Data Representation**:\n   - The ratings are stored in a matrix 𝑌, where each element 𝑦(𝑖,𝑗) represents the rating given by user j to movie i. If the movie has not been rated, the element is 0.\n   - The matrix 𝐑 is a binary indicator matrix where each element 𝑟(𝑖,𝑗) is 1 if user j has rated movie i, and 0 otherwise.\n\n2. **Vector Learning**:\n   - Each user has a parameter vector 𝐰(𝑗) and a bias term 𝑏(𝑗).\n   - Each movie has a feature vector 𝐱(𝑖).\n   - These vectors are learned by using the existing ratings in 𝑌 as training data.\n\n3. **Prediction**:\n   - Once the vectors are learned, the predicted rating for user j on movie i is given by the dot product of 𝐰(𝑗) and 𝐱(𝑖), plus the bias term 𝑏(𝑗):\n     \\[\n     \\text{Predicted Rating} = 𝐰(𝑗) \\cdot 𝐱(𝑖) + 𝑏(𝑗)\n     \\]\n   - This allows the system to predict ratings for unrated movies and recommend movies to users based on these predictions.\n\n### Training the Model\nThe training process involves optimizing the parameters to minimize the difference between the predicted and actual ratings. This is achieved using gradient descent, where the cost function includes a regularization term to prevent overfitting.\n\n### Implementation in TensorFlow\nThe collaborative filtering algorithm is implemented in TensorFlow, utilizing a custom training loop to optimize the parameters. The key components include:\n- **Cost Function**: Computes the error between predicted and actual ratings, including a regularization term.\n- **Gradient Descent**: Iteratively updates the parameters to minimize the cost function.\n\nBy following these steps, the collaborative filtering recommendation system can effectively learn from user ratings and provide personalized movie recommendations.\n\n---","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:02.254715Z","iopub.execute_input":"2024-07-03T14:09:02.255558Z","iopub.status.idle":"2024-07-03T14:09:02.261007Z","shell.execute_reply.started":"2024-07-03T14:09:02.255520Z","shell.execute_reply":"2024-07-03T14:09:02.259641Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Read the csv\nrating=pd.read_csv('/kaggle/input/anime-recommendation-database-2020/rating_complete.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:02.272252Z","iopub.execute_input":"2024-07-03T14:09:02.272710Z","iopub.status.idle":"2024-07-03T14:09:20.695159Z","shell.execute_reply.started":"2024-07-03T14:09:02.272673Z","shell.execute_reply":"2024-07-03T14:09:20.694150Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Due to the large size of the data and the limitations of my computing memory, I decided to sample 10,000 rows to create the pivot table for ratings.","metadata":{}},{"cell_type":"code","source":"# Sample the data\nrating = rating.sample(n=10000,random_state=44)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:20.697169Z","iopub.execute_input":"2024-07-03T14:09:20.697537Z","iopub.status.idle":"2024-07-03T14:09:24.532990Z","shell.execute_reply.started":"2024-07-03T14:09:20.697506Z","shell.execute_reply":"2024-07-03T14:09:24.532079Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Pivot the data\nrating_pivot = rating.pivot(index='anime_id', columns='user_id', values='rating')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:24.534141Z","iopub.execute_input":"2024-07-03T14:09:24.534442Z","iopub.status.idle":"2024-07-03T14:09:24.698652Z","shell.execute_reply.started":"2024-07-03T14:09:24.534417Z","shell.execute_reply":"2024-07-03T14:09:24.697499Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"rating_pivot","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:24.701540Z","iopub.execute_input":"2024-07-03T14:09:24.701910Z","iopub.status.idle":"2024-07-03T14:09:24.736685Z","shell.execute_reply.started":"2024-07-03T14:09:24.701881Z","shell.execute_reply":"2024-07-03T14:09:24.735469Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"user_id   25      53      64      119     162     169     216     331     \\\nanime_id                                                                   \n1            NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n5            NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n6            NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n7            NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n15           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n...          ...     ...     ...     ...     ...     ...     ...     ...   \n42958        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n42984        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n43467        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n43690        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n45753        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n\nuser_id   372     409     ...  353012  353023  353040  353055  353098  353134  \\\nanime_id                  ...                                                   \n1            NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n5            NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n6            NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n7            NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n15           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n...          ...     ...  ...     ...     ...     ...     ...     ...     ...   \n42958        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n42984        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n43467        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n43690        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n45753        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n\nuser_id   353139  353181  353232  353294  \nanime_id                                  \n1            NaN     NaN     NaN     NaN  \n5            NaN     NaN     NaN     NaN  \n6            NaN     NaN     NaN     NaN  \n7            NaN     NaN     NaN     NaN  \n15           NaN     NaN     NaN     NaN  \n...          ...     ...     ...     ...  \n42958        NaN     NaN     NaN     NaN  \n42984        NaN     NaN     NaN     NaN  \n43467        NaN     NaN     NaN     NaN  \n43690        NaN     NaN     NaN     NaN  \n45753        NaN     NaN     NaN     NaN  \n\n[3395 rows x 9588 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>user_id</th>\n      <th>25</th>\n      <th>53</th>\n      <th>64</th>\n      <th>119</th>\n      <th>162</th>\n      <th>169</th>\n      <th>216</th>\n      <th>331</th>\n      <th>372</th>\n      <th>409</th>\n      <th>...</th>\n      <th>353012</th>\n      <th>353023</th>\n      <th>353040</th>\n      <th>353055</th>\n      <th>353098</th>\n      <th>353134</th>\n      <th>353139</th>\n      <th>353181</th>\n      <th>353232</th>\n      <th>353294</th>\n    </tr>\n    <tr>\n      <th>anime_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42958</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42984</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>43467</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>43690</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45753</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3395 rows × 9588 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create a pivot that flagged the not null values in rating_pivot\nbinary_pivot = rating_pivot.notna().astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:24.738066Z","iopub.execute_input":"2024-07-03T14:09:24.738417Z","iopub.status.idle":"2024-07-03T14:09:24.855460Z","shell.execute_reply.started":"2024-07-03T14:09:24.738387Z","shell.execute_reply":"2024-07-03T14:09:24.854185Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Define the variable\nY=np.array(rating_pivot)\nR=np.array(binary_pivot)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:24.856819Z","iopub.execute_input":"2024-07-03T14:09:24.857179Z","iopub.status.idle":"2024-07-03T14:09:25.058216Z","shell.execute_reply.started":"2024-07-03T14:09:24.857151Z","shell.execute_reply":"2024-07-03T14:09:25.056920Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Set dimensions\nnum_users,num_movies = Y.shape\nnum_features = 20\n\n# Initialize X, W, and b with random values\nX = np.random.rand(num_movies, num_features)\nW = np.random.rand(num_users, num_features)\nb = np.random.rand(1, num_users)\n\n# Display shapes to confirm the correct initialization\nprint(\"Shape of Y:\", Y.shape)\nprint(\"Shape of R:\", R.shape)\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of W:\", W.shape)\nprint(\"Shape of b:\", b.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.059758Z","iopub.execute_input":"2024-07-03T14:09:25.060162Z","iopub.status.idle":"2024-07-03T14:09:25.071883Z","shell.execute_reply.started":"2024-07-03T14:09:25.060130Z","shell.execute_reply":"2024-07-03T14:09:25.070667Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Shape of Y: (3395, 9588)\nShape of R: (3395, 9588)\nShape of X: (9588, 20)\nShape of W: (3395, 20)\nShape of b: (1, 3395)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now that we have defined all the necessary variables, we will compute the average rating for movie 1.","metadata":{}},{"cell_type":"code","source":"#  From the matrix, we can compute statistics like average rating.\ntsmean =  np.mean(Y[0, R[0, :].astype(bool)])\nprint(f\"Average rating for movie 1 : {tsmean:0.3f} / 10\" )","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.073451Z","iopub.execute_input":"2024-07-03T14:09:25.073898Z","iopub.status.idle":"2024-07-03T14:09:25.081807Z","shell.execute_reply.started":"2024-07-03T14:09:25.073861Z","shell.execute_reply":"2024-07-03T14:09:25.080524Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Average rating for movie 1 : 9.143 / 10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Create Cost Function","metadata":{}},{"cell_type":"code","source":"def cofi_cost_func(X, W, b, Y, R, lambda_):\n    \"\"\"\n    Returns the cost for the content-based filtering\n    Args:\n      X (ndarray (num_movies,num_features)): matrix of item features\n      W (ndarray (num_users,num_features)) : matrix of user parameters\n      b (ndarray (1, num_users)            : vector of user parameters\n      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n      lambda_ (float): regularization parameter\n    Returns:\n      J (float) : Cost\n    \"\"\"\n    nm, nu = Y.shape\n    J = 0\n    \n    for i in range(nm):\n        for j in range(nu):\n            if R[i, j] == 1:\n                pred_rating = np.dot(W[j, :], X[i, :]) + b[0, j]\n                \n                error = pred_rating - Y[i, j]\n                \n                J +=  error**2\n    \n    reg_X = lambda_ / 2 * np.sum(X**2)\n    reg_W = lambda_ / 2 * np.sum(W**2)\n    \n    J =J/2\n    J +=reg_X + reg_W     \n\n    return J","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.083288Z","iopub.execute_input":"2024-07-03T14:09:25.083748Z","iopub.status.idle":"2024-07-03T14:09:25.095144Z","shell.execute_reply.started":"2024-07-03T14:09:25.083707Z","shell.execute_reply":"2024-07-03T14:09:25.093796Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Reduce the data set size so that this runs faster\nnum_users_r = 1910\nnum_movies_r = 5 \nnum_features_r = 3\n\nX_r = X[:num_movies_r, :num_features_r]\nW_r = W[:num_users_r,  :num_features_r]\nb_r = b[0, :num_users_r].reshape(1,-1)\nY_r = Y[:num_movies_r, :num_users_r]\nY_r = tf.where(tf.math.is_nan(Y_r), tf.zeros_like(Y_r), Y_r)\nR_r = R[:num_movies_r, :num_users_r]\n\n# Evaluate cost function\nJ = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\nprint(f\"Cost: {J:0.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.099740Z","iopub.execute_input":"2024-07-03T14:09:25.100161Z","iopub.status.idle":"2024-07-03T14:09:25.130859Z","shell.execute_reply.started":"2024-07-03T14:09:25.100126Z","shell.execute_reply":"2024-07-03T14:09:25.129749Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Cost: 192.95\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate cost function with regularization \nJ = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\nprint(f\"Cost (with regularization): {J:0.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.132326Z","iopub.execute_input":"2024-07-03T14:09:25.132754Z","iopub.status.idle":"2024-07-03T14:09:25.151687Z","shell.execute_reply.started":"2024-07-03T14:09:25.132710Z","shell.execute_reply":"2024-07-03T14:09:25.150562Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Cost (with regularization): 1620.25\n","output_type":"stream"}]},{"cell_type":"code","source":"def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n    \"\"\"\n    Returns the cost for the content-based filtering\n    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n    Args:\n      X (ndarray (num_movies,num_features)): matrix of item features\n      W (ndarray (num_users,num_features)) : matrix of user parameters\n      b (ndarray (1, num_users)            : vector of user parameters\n      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n      lambda_ (float): regularization parameter\n    Returns:\n      J (float) : Cost\n    \"\"\"\n    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n    return J","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.153157Z","iopub.execute_input":"2024-07-03T14:09:25.153591Z","iopub.status.idle":"2024-07-03T14:09:25.161673Z","shell.execute_reply.started":"2024-07-03T14:09:25.153553Z","shell.execute_reply":"2024-07-03T14:09:25.160465Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Evaluate cost function\nJ = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 0);\nprint(f\"Cost: {J:0.2f}\")\n\n# Evaluate cost function with regularization \nJ = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 1.5);\nprint(f\"Cost (with regularization): {J:0.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.163241Z","iopub.execute_input":"2024-07-03T14:09:25.163622Z","iopub.status.idle":"2024-07-03T14:09:25.187020Z","shell.execute_reply.started":"2024-07-03T14:09:25.163585Z","shell.execute_reply":"2024-07-03T14:09:25.185808Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Cost: 192.95\nCost (with regularization): 1620.25\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Add my rating","metadata":{}},{"cell_type":"code","source":"my_ratings = np.zeros(num_movies)          #  Initialize my ratings\n\nmy_ratings[241] = 5 \nmy_ratings[2609] = 2;\nmy_ratings[929]  = 9 \nmy_ratings[246]  = 8   \nmy_ratings[216] = 3  \nmy_ratings[110] = 6  \nmy_ratings[382]  = 7  \nmy_ratings[366]  = 4  \nmy_ratings[622]  = 2  \nmy_ratings[988]  = 1  \nmy_ratings[263] = 10  \nmy_ratings[293] = 9  \nmy_ratings[793]  = 7   \nmy_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.188274Z","iopub.execute_input":"2024-07-03T14:09:25.188597Z","iopub.status.idle":"2024-07-03T14:09:25.200273Z","shell.execute_reply.started":"2024-07-03T14:09:25.188570Z","shell.execute_reply":"2024-07-03T14:09:25.199116Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"print('Y:',Y.T.shape)\nprint('my_ratings:',my_ratings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.201857Z","iopub.execute_input":"2024-07-03T14:09:25.202883Z","iopub.status.idle":"2024-07-03T14:09:25.209088Z","shell.execute_reply.started":"2024-07-03T14:09:25.202849Z","shell.execute_reply":"2024-07-03T14:09:25.207812Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Y: (9588, 3395)\nmy_ratings: (9588,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Concatenate my_ratings with Y\nY = np.c_[my_ratings, Y.T]\n\n# Update the indicator matrix R accordingly\nR_new_user = (my_ratings != 0).astype(int)\nR = np.c_[R_new_user, R.T]\n\nY=Y.T\nR=R.T","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.210668Z","iopub.execute_input":"2024-07-03T14:09:25.211594Z","iopub.status.idle":"2024-07-03T14:09:25.412207Z","shell.execute_reply.started":"2024-07-03T14:09:25.211562Z","shell.execute_reply":"2024-07-03T14:09:25.411216Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"Now that we have defined all the necessary variables, we will compute the average rating for movie 1.\n\n---\n\nTo address the cold start problem for new users who have not provided any ratings, we can utilize rating normalization to generate a baseline prediction for users with no ratings.\n\n### Why Normalize Ratings in Collaborative Filtering?\nNormalization helps in collaborative filtering by ensuring that the ratings are adjusted to a common scale, reducing bias and improving the accuracy of predictions. Here's why it's important:\n1. **Consistent Scale**: Normalizing ratings ensures that all user ratings are on a consistent scale, allowing the model to make fair comparisons across different users and movies.\n2. **Bias Reduction**: It reduces the bias introduced by users who rate movies more generously or harshly compared to others.\n3. **Cold Start Problem**: For new users with no ratings, normalization provides a baseline prediction by adjusting for the average rating, helping to make initial recommendations.\n\nBy normalizing ratings, we can create a more accurate and fair collaborative filtering model, enhancing its ability to make predictions for all users, including new ones.\n","metadata":{}},{"cell_type":"code","source":"def normalizeRatings(Y, R):\n    \"\"\"\n    Normalize Y so that each movie has a mean rating of 0, and return the mean rating in Ymean.\n    Args:\n    Y -- (num_movies, num_users) matrix of movie ratings\n    R -- (num_movies, num_users) matrix, where R(i, j) = 1 if and only if user j gave a rating to movie i\n\n    Returns:\n    Ynorm -- normalized Y matrix\n    Ymean -- mean rating for each movie\n    \"\"\"\n    num_movies = Y.shape[0]\n    Ymean = np.zeros((num_movies, 1))\n    Ynorm = np.zeros_like(Y)\n\n    for i in range(num_movies):\n        idx = np.where(R[i] == 1)[0]\n        if len(idx) > 0:\n            Ymean[i] = np.mean(Y[i, idx])\n            Ynorm[i, idx] = Y[i, idx] - Ymean[i]\n        else:\n            Ymean[i] = 0\n            Ynorm[i, :] = 0\n\n    return Ynorm, Ymean","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.413488Z","iopub.execute_input":"2024-07-03T14:09:25.413860Z","iopub.status.idle":"2024-07-03T14:09:25.422559Z","shell.execute_reply.started":"2024-07-03T14:09:25.413831Z","shell.execute_reply":"2024-07-03T14:09:25.421238Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Normalize the Dataset\nYnorm, Ymean = normalizeRatings(Y, R)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.424156Z","iopub.execute_input":"2024-07-03T14:09:25.424523Z","iopub.status.idle":"2024-07-03T14:09:25.631539Z","shell.execute_reply.started":"2024-07-03T14:09:25.424493Z","shell.execute_reply":"2024-07-03T14:09:25.630633Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Create a custom function using tensorflow","metadata":{}},{"cell_type":"code","source":"#  Useful Values\nnum_movies, num_users = Y.shape\nnum_features = 100\n\n# Set Initial Parameters (W, X), use tf.Variable to track these variables\ntf.random.set_seed(1234) # for consistent results\nW = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\nX = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\nb = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n\n# Instantiate an optimizer.\noptimizer = keras.optimizers.Adam(learning_rate=1e-1)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.632750Z","iopub.execute_input":"2024-07-03T14:09:25.633099Z","iopub.status.idle":"2024-07-03T14:09:25.667852Z","shell.execute_reply.started":"2024-07-03T14:09:25.633071Z","shell.execute_reply":"2024-07-03T14:09:25.666723Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"iterations = 450\nlambda_ = 0.5\nfor iter in range(iterations):\n    with tf.GradientTape() as tape:\n\n        # Compute the cost\n        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n\n    # Use the gradient tape to automatically retrieve\n    # the gradients of the trainable variables with respect to the loss\n    grads = tape.gradient( cost_value, [X,W,b] )\n\n    # Run one step of gradient descent by updating\n    # the value of the variables to minimize the loss.\n    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n\n    # Log periodically.\n    if iter % 20 == 0:\n        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:09:25.669673Z","iopub.execute_input":"2024-07-03T14:09:25.670066Z","iopub.status.idle":"2024-07-03T14:14:59.351052Z","shell.execute_reply.started":"2024-07-03T14:09:25.670036Z","shell.execute_reply":"2024-07-03T14:14:59.350063Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Training loss at iteration 0: 835064.5\nTraining loss at iteration 20: 155965.0\nTraining loss at iteration 40: 67725.2\nTraining loss at iteration 60: 33735.1\nTraining loss at iteration 80: 18275.8\nTraining loss at iteration 100: 10549.5\nTraining loss at iteration 120: 6458.7\nTraining loss at iteration 140: 4173.1\nTraining loss at iteration 160: 2815.6\nTraining loss at iteration 180: 1959.3\nTraining loss at iteration 200: 1393.6\nTraining loss at iteration 220: 1008.5\nTraining loss at iteration 240: 741.6\nTraining loss at iteration 260: 554.7\nTraining loss at iteration 280: 422.7\nTraining loss at iteration 300: 329.1\nTraining loss at iteration 320: 262.4\nTraining loss at iteration 340: 214.8\nTraining loss at iteration 360: 180.7\nTraining loss at iteration 380: 156.4\nTraining loss at iteration 400: 139.3\nTraining loss at iteration 420: 127.2\nTraining loss at iteration 440: 118.9\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model variables\nnp.savez('cofi_model8.npz', W=W.numpy(), X=X.numpy(), b=b.numpy(), Ymean=Ymean)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:14:59.352768Z","iopub.execute_input":"2024-07-03T14:14:59.353145Z","iopub.status.idle":"2024-07-03T14:14:59.478538Z","shell.execute_reply.started":"2024-07-03T14:14:59.353113Z","shell.execute_reply":"2024-07-03T14:14:59.477369Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Test the model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Make a prediction using trained weights and biases\np = np.matmul(X, np.transpose(W)) + b\n\n# Restore the mean by adding Ymean (broadcasting correctly)\n# Since p is (2633, 5855) and Ymean is (2633, 1), broadcasting will automatically work\npm = p + Ymean\n\nmy_predictions = pm[:, 0]\n\n# Sort predictions\nix = np.argsort(my_predictions)[::-1]  \n\n# Sample movieList for demonstration\nmovieList = [f\"Movie {i}\" for i in range(num_movies)]\n\n# Assume my_rated contains the indices of movies rated by the user\nmy_rated = np.where(my_ratings > 0)[0]\n\nprint('\\nTop Predictions for New User:\\n')\nfor i in range(17):\n    j = ix[i]\n    if j not in my_rated:\n        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n\nprint('\\n\\nOriginal vs Predicted ratings:\\n')\nfor i in range(len(my_ratings)):\n    if my_ratings[i] > 0:\n        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:14:59.522287Z","iopub.execute_input":"2024-07-03T14:14:59.522676Z","iopub.status.idle":"2024-07-03T14:15:00.144524Z","shell.execute_reply.started":"2024-07-03T14:14:59.522645Z","shell.execute_reply":"2024-07-03T14:15:00.143372Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"\nTop Predictions for New User:\n\nPredicting rating 8.67 for movie Movie 472\nPredicting rating 8.67 for movie Movie 2771\nPredicting rating 8.67 for movie Movie 1170\nPredicting rating 8.67 for movie Movie 30\nPredicting rating 8.67 for movie Movie 3132\nPredicting rating 8.67 for movie Movie 701\nPredicting rating 8.67 for movie Movie 2478\nPredicting rating 8.67 for movie Movie 4\nPredicting rating 8.67 for movie Movie 1708\nPredicting rating 8.67 for movie Movie 2810\nPredicting rating 8.67 for movie Movie 3337\nPredicting rating 8.67 for movie Movie 3078\nPredicting rating 8.67 for movie Movie 460\nPredicting rating 8.67 for movie Movie 1496\nPredicting rating 8.67 for movie Movie 1703\nPredicting rating 8.67 for movie Movie 1342\nPredicting rating 8.67 for movie Movie 2377\n\n\nOriginal vs Predicted ratings:\n\nOriginal 6.0, Predicted 5.33 for Movie 110\nOriginal 3.0, Predicted 5.77 for Movie 216\nOriginal 5.0, Predicted 7.13 for Movie 241\nOriginal 8.0, Predicted 7.67 for Movie 246\nOriginal 10.0, Predicted 2.67 for Movie 263\nOriginal 9.0, Predicted 6.17 for Movie 293\nOriginal 4.0, Predicted 3.67 for Movie 366\nOriginal 7.0, Predicted 6.00 for Movie 382\nOriginal 2.0, Predicted 5.67 for Movie 622\nOriginal 7.0, Predicted 5.67 for Movie 793\nOriginal 9.0, Predicted 6.67 for Movie 929\nOriginal 1.0, Predicted 8.67 for Movie 988\nOriginal 2.0, Predicted 6.67 for Movie 2609\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Conclusion\nThis notebook demonstrates the implementation of a collaborative filtering recommendation system using TensorFlow. It covers data preprocessing, defining the cost function, training the model, and making predictions. Adjust the parameters and input data as needed for your specific use case.","metadata":{}}]}